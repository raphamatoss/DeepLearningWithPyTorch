{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpdvSQFjdslCeiot+Kx0rJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raphamatoss/DeepLearningWithPyTorch/blob/main/IntroductionToTensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTRODUCTION TO TENSORS**\n",
        "\n",
        "A tensor is basically a generalization of mathematical values. Everything can be a tensor, a scalar, a vector or a matrix. Any R^n matrix is also a tensor!\n",
        "\n",
        "Pytorch tensor documentation: https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "We can create tensors with pytorch as it follows:"
      ],
      "metadata": {
        "id": "nFDSsP1hxJIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4jdpMvVt015",
        "outputId": "275be660-266a-4a31-c811-ee4c75734588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar tensor: \n",
            "tensor(7)\n",
            "\n",
            "Vector tensor: \n",
            "tensor([2, 2, 2, 2])\n",
            "\n",
            "Matrix tensor: \n",
            "tensor([[1, 1],\n",
            "        [2, 2],\n",
            "        [3, 3]])\n",
            "\n",
            "Multi-dimensional tensor: \n",
            "tensor([[[1, 1],\n",
            "         [2, 2],\n",
            "         [1, 1],\n",
            "         [2, 2]]])\n",
            "\n",
            "Tensor using a numpy array: \n",
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# all of the four variables above are examples of tensors!\n",
        "scalar = torch.tensor(7);\n",
        "vector = torch.tensor([2, 2, 2, 2])\n",
        "matrix = torch.tensor([[1, 1], [2,2],[3, 3]])\n",
        "tensor = torch.tensor([[[1,1], [2, 2], [1, 1], [2, 2]]])\n",
        "\n",
        "print(\"Scalar tensor: \")\n",
        "print(scalar)\n",
        "print(\"\\nVector tensor: \")\n",
        "print(vector)\n",
        "print(\"\\nMatrix tensor: \")\n",
        "print(matrix)\n",
        "print(\"\\nMulti-dimensional tensor: \")\n",
        "print(tensor)\n",
        "\n",
        "# a torch tensor may also be initialized with a numpy array\n",
        "import numpy as np\n",
        "matrix_2 = torch.tensor(np.array([[1, 1 ,1], [2, 2, 2]]))\n",
        "\n",
        "print(\"\\nTensor using a numpy array: \")\n",
        "print(matrix_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimension/Rank**"
      ],
      "metadata": {
        "id": "LwV8LuliD6eB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every tensor has a **dimension**(also called **rank**), which stands for the number of indexes it is required to acess its information.\n",
        "\n",
        "A **scalar has dimension 0**, since it isn't required any indexes to describe its value.\n",
        "\n",
        "A **vector has dimension 1**, since it is required 1 index to describe its value\n",
        "\n",
        "A **matrix has dimension 2**, since it is required 2 indexes to describe its values.\n",
        "\n",
        "And so on. On Pytorch we can get the dimension of a tensor using the `.ndim`."
      ],
      "metadata": {
        "id": "aR8Cx2na3LU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_clLs0b4M5n",
        "outputId": "d1849e68-0516-4c65-db7b-c7da6bc993ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGtQr-h54XJf",
        "outputId": "ab902b2a-68ab-4ac7-8543-fa41345e7cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-EZteUm4aFv",
        "outputId": "7cca43dd-94a9-4fff-f001-9e265754b5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape/Size**"
      ],
      "metadata": {
        "id": "-vjcTeNOECOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors also have a **shape**(also called size). The shape of a tensor is related to its dimension, it represents the length of each dimension"
      ],
      "metadata": {
        "id": "UHwXgKVh-xse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[[1, 1],\n",
        "                        [2, 2],\n",
        "                        [1, 1],\n",
        "                        [2, 2]]])\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jOyIR6d_d8y",
        "outputId": "94dcbdf5-586f-46a9-d7e3-a4c271a287fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data type**"
      ],
      "metadata": {
        "id": "RW4ab_DsEGFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to specify the data type of a tensor, we can define `torch.dtype` in the `torch.tensor()` constructor:"
      ],
      "metadata": {
        "id": "xl80LnK3t6Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "integer_tensor = torch.tensor([1, 1, 1], dtype=torch.int16)\n",
        "print(integer_tensor)\n",
        "\n",
        "# If we want to get the type of a tensor we can do as it follows:\n",
        "integer_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4Up9kuP2DkY",
        "outputId": "cc91d14d-0cd9-464b-bba2-f2f4f4642653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1], dtype=torch.int16)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int16"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor datatypes is one of the 3 big erros we may run into with PyTorch and DP:\n",
        "1. Tensors not in the right datatype\n",
        "2. Tensors not in the right shape\n",
        "3. Tensors not on the right device"
      ],
      "metadata": {
        "id": "GL7dCHPQP0D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 32 tensor is the standart tensor datatype when creating\n",
        "# tensors with PyTorch\n",
        "float_32 = torch.zeros(dtype=None, # what datatype the tensor is\n",
        "                       device=None, # what device the tensor is on(Nvidia cuda, Tpu)\n",
        "                       requires_grad=False) # wheter or not to track gradients with this tensors operations"
      ],
      "metadata": {
        "id": "FR7EVnpAQKWh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "92e8ad1d-57b9-40f2-85e9-c4cd61afae58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "zeros() received an invalid combination of arguments - got (requires_grad=bool, device=NoneType, dtype=NoneType, ), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-01b157127284>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Float 32 tensor is the standart tensor datatype when creating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# tensors with PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m float_32 = torch.zeros(dtype=None, # what datatype the tensor is\n\u001b[0m\u001b[1;32m      4\u001b[0m                        \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# what device the tensor is on(Nvidia cuda, Tpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        requires_grad=False) # wheter or not to track gradients with this tensors operations\n",
            "\u001b[0;31mTypeError\u001b[0m: zeros() received an invalid combination of arguments - got (requires_grad=bool, device=NoneType, dtype=NoneType, ), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Tensors**\n",
        "\n",
        "Random tensors are important because many neural networks start with random weights and adjust them to better values along the training step.\n",
        "\n",
        "We can create random tensors using `torch.rand().`"
      ],
      "metadata": {
        "id": "vXoq67OtAs8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can create a tensor of a desired shape by specifing it\n",
        "# in the constructor\n",
        "random_tensor = torch.rand(2, 3, 4)\n",
        "random_tensor"
      ],
      "metadata": {
        "id": "fWqBkS4TBlul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "id": "Dlm1uvdWCLLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeros and ones**"
      ],
      "metadata": {
        "id": "lds1tENLDOlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also create tensors filled with zeros or ones\n",
        "zeros = torch.zeros(3, 3)\n",
        "zeros"
      ],
      "metadata": {
        "id": "pkO9QOBKDTlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(3, 3)\n",
        "ones"
      ],
      "metadata": {
        "id": "RKCoNzP9DdCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Range of tensors**\n",
        "\n",
        "Using `torch.arange(start, end, step)` we can create a 1D tensor with values from a specified interval."
      ],
      "metadata": {
        "id": "kTaQAwrsHux-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can define only the start and end parameters\n",
        "one_to_ten = torch.arange(1, 11)\n",
        "one_to_ten"
      ],
      "metadata": {
        "id": "lS4jT6dzIkJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# besides the start and end parameters, we can also define the step\n",
        "one_to_hundred = torch.arange(0, 101, 5)\n",
        "one_to_hundred"
      ],
      "metadata": {
        "id": "vsnszbcfIxhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors Like**\n",
        "\n",
        "`torch.zeros_like(input)`\n",
        "`torch.ones_like(input)`\n",
        "`torch.rand_like(input)`\n",
        "\n",
        "All of these pytorch methods return a tensor of the same shape as the input tensor."
      ],
      "metadata": {
        "id": "Lui1h_lPJsTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(1, 2, 5)\n",
        "tensor"
      ],
      "metadata": {
        "id": "Wt0dn9uPLsqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_like = torch.zeros_like(tensor)\n",
        "zeros_like"
      ],
      "metadata": {
        "id": "kunbOSZFMSuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones_like = torch.ones_like(tensor)\n",
        "ones_like"
      ],
      "metadata": {
        "id": "USgPi0vmMe7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_like = torch.rand_like(tensor)\n",
        "rand_like"
      ],
      "metadata": {
        "id": "tEF3unzHMjvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TENSOR OPERATIONS**\n",
        "1. Addition/Subtraction\n",
        "2. Multiplication/Division\n",
        "3. Matrix multiplication"
      ],
      "metadata": {
        "id": "YoYoRdnwTsGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# addition\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 100"
      ],
      "metadata": {
        "id": "b05ITY11T559"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(tensor, 100)"
      ],
      "metadata": {
        "id": "GHtrp4DTUirL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.add(10)"
      ],
      "metadata": {
        "id": "2bzfHnEGUzKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiplication\n",
        "tensor * 2"
      ],
      "metadata": {
        "id": "3RD4zXnIUBFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mul(tensor, 2)"
      ],
      "metadata": {
        "id": "Y_Tos-oBUn7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.mul(2)"
      ],
      "metadata": {
        "id": "rkh0RKl6UwfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Multiplication**\n",
        "\n",
        "Matrix multiplication uses the **dot product**, that means that to multiply a **m**x**n** matrix by a **n**x**p** matrix, the **n**s must be the same and it will result in a **m**x**p** matrix:\n",
        "1. `(3, 2) @ (3, 2)` cannot be calculated\n",
        "2. `(3, 2) @ (2, 3)` can be calculated -> `(3, 3)`\n",
        "3. `(2, 3) @ (3, 2)` can be calculated -> `(2, 2)`"
      ],
      "metadata": {
        "id": "3jmlzWdRaSgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "id": "I-CrzXshaxLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = torch.tensor([[2, 2, 2], [3, 3, 3]])\n",
        "tensor_2 = torch.tensor([5, 5, 5])\n",
        "torch.matmul(tensor_1, tensor_2)"
      ],
      "metadata": {
        "id": "zRhbKIkQa7B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to multiply tensors of incompatible shapes, we can manipulate the shape of one of our tensors using a **transpose**.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor.\n"
      ],
      "metadata": {
        "id": "671JlGyfmxbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = torch.rand(3, 2)\n",
        "tensor_2 = torch.rand(3, 2)\n",
        "# the shape of the tensors above do not match, so if we try to run\n",
        "# torch.mm(tensor_1, tensor_2) we will get an error, to fix this issue\n",
        "# we can transpose one of our tensors:\n",
        "tensor_1"
      ],
      "metadata": {
        "id": "dnyefg6GnL1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by adding \".T\" at the end, we get the transposed tensor\n",
        "tensor_1.T"
      ],
      "metadata": {
        "id": "fGgVQz_wnu8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with that in mind, we can now multiply our tensors\n",
        "torch.mm(tensor_1.T, tensor_2)"
      ],
      "metadata": {
        "id": "-iK7xSUCn4JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original shape: tensor_1 = {tensor_1.shape}, tensor_2 = {tensor_2.shape}\")\n",
        "print(f\"Fixed shape: tensor_1 = {tensor_1.T.shape}, tensor_2 = {tensor_2.shape}\")"
      ],
      "metadata": {
        "id": "KEZV5WAbokZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Min, max, mean and sum of a tensor**"
      ],
      "metadata": {
        "id": "9tRsRRfZwDSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(0, 101, 10)\n",
        "tensor"
      ],
      "metadata": {
        "id": "KaEtwFFvwIwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## min:\n",
        "torch.min(tensor), tensor.min()"
      ],
      "metadata": {
        "id": "eAsAPTTVwezG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## max:\n",
        "torch.max(tensor), tensor.max()"
      ],
      "metadata": {
        "id": "ZCeQm84awmm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## mean:\n",
        "tensor = tensor.type(torch.float32)\n",
        "# the input tensor of the torch.mean must be a float or a complex\n",
        "torch.mean(tensor), tensor.mean()"
      ],
      "metadata": {
        "id": "oUvsZTTkwrt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sum:\n",
        "torch.sum(tensor), tensor.sum()"
      ],
      "metadata": {
        "id": "7SfNMokFyVKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional min and max of a tensor**\n",
        "\n",
        "It is the index which holds the min/max value"
      ],
      "metadata": {
        "id": "ue-hpRwNy-7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "id": "SJf6njt4zI2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positional min = torch.argmin() -> returns the index of the min value within the tensor\n",
        "torch.argmin(tensor), tensor.argmin()"
      ],
      "metadata": {
        "id": "WEWSOL1jzNjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positional max = torch.argmax() -> returns the index of the max value within the tensor\n",
        "torch.argmax(tensor), tensor.argmax()"
      ],
      "metadata": {
        "id": "-xkbXNWEzSc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshape, stack, squeeze and unsqueeze tensors**\n",
        "\n",
        "**Reshape:** reshapes an input tensor to a defined shape, it is required that the new shape is compatible with the old one\n",
        "\n",
        "**View:** returns a view of an input tensor of certain shape but shares the memory with input, that means changing the view will also affect the original input\n",
        "\n",
        "**Stack:** concatenates a sequence of tensors along a new dimension. All tensors must be of the same size. There is a vstack for vertical stack and a hstack for horizontal stack.\n",
        "\n",
        "**Squeeze:** removes all \"1\" dimensions from a tensor. The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contentes of other.\n",
        "\n",
        "**Unsqueeze:** adds a \"1\" dimension to a target tensor. The returned tensor also shares the storage with the input tensor.\n",
        "\n",
        "**Permute:** returns a view of the input with dimensions permuted in a specified order\n"
      ],
      "metadata": {
        "id": "HZt9Cq750k0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "## reshaping\n",
        "tensor = torch.zeros(5)\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtmlphRIAQQD",
        "outputId": "f02be3d4-9277-4a89-ad5b-c718d41c48f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it works since 1*5 = 5, which is the original shape\n",
        "tensor.reshape(1, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU2luj9fAcWk",
        "outputId": "7f94c954-a9c8-40c3-fb66-350380fcfd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but if instead we try 2*5 = 10, it won't work, since 10 is double the size of the original\n",
        "tensor.reshape(2, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "nkeTYkayAle0",
        "outputId": "c1cd6962-f3e7-4d9c-8e55-ca2bc924c056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[2, 5]' is invalid for input of size 5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4038146705eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# but if instead we try 2*5 = 10, it won't work, since 10 is double the size of the original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 5]' is invalid for input of size 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## view\n",
        "x = tensor.view(1, 5)\n",
        "x[0][0] = 5 # changing the view will also change the original tensor\n",
        "y = tensor.reshape(5) # since the original was changed, we'll notice the changes here\n",
        "x, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfanjNHEBS-2",
        "outputId": "63602953-ccb0-4584-8929-3a49802ae888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 5., 0., 0., 0.]]), tensor([5., 5., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## stacking tensors\n",
        "tensor_a = torch.rand(5)\n",
        "tensor_b = torch.rand(5)\n",
        "stacked_tensor = torch.stack([tensor_a, tensor_b], dim=0)\n",
        "tensor_a, tensor_b, stacked_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iV5-uqEFQG-",
        "outputId": "aaac9662-343d-4a72-c555-55198c7e3123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.6602, 0.1583, 0.7621, 0.8695, 0.8574]),\n",
              " tensor([0.5930, 0.6247, 0.1203, 0.3678, 0.2650]),\n",
              " tensor([[0.6602, 0.1583, 0.7621, 0.8695, 0.8574],\n",
              "         [0.5930, 0.6247, 0.1203, 0.3678, 0.2650]]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_tensor = torch.stack([tensor_a, tensor_b], dim=1)\n",
        "stacked_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGvPvtfMFvE1",
        "outputId": "8fee211d-f165-460f-e5a5-0b656419e1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6602, 0.5930],\n",
              "        [0.1583, 0.6247],\n",
              "        [0.7621, 0.1203],\n",
              "        [0.8695, 0.3678],\n",
              "        [0.8574, 0.2650]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## squeezing tensors\n",
        "tensor = torch.zeros(2, 1, 2, 1, 2)\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMMHBRNKHFtI",
        "outputId": "0ff8cb30-ea28-453a-a409-22702ad0808e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.squeeze(tensor)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEonQSsVH8fU",
        "outputId": "37af35aa-3986-473c-852e-6b106bbfb345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also select which dimension we want to squeeze\n",
        "x = torch.squeeze(tensor, 1)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOL-ywUoIu-V",
        "outputId": "1ad5a8f1-cbf7-46eb-cf39-ef52e4b47758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since their storage are shared, if we change the content of one, both are affected\n",
        "tensor[0][0][0][0][0] = 1\n",
        "tensor, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnrr14akIC04",
        "outputId": "4bbf7884-e688-4c00-988b-4c0c6f5dd31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[[1., 0.]],\n",
              " \n",
              "           [[0., 0.]]]],\n",
              " \n",
              " \n",
              " \n",
              "         [[[[0., 0.]],\n",
              " \n",
              "           [[0., 0.]]]]]),\n",
              " tensor([[[1., 0.],\n",
              "          [0., 0.]],\n",
              " \n",
              "         [[0., 0.],\n",
              "          [0., 0.]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## unsqueezing tensors\n",
        "tensor = torch.zeros(2, 2)\n",
        "\n",
        "unsqueezed_tensor = torch.unsqueeze(tensor, 0)\n",
        "tensor.shape, unsqueezed_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6PFFbfHNWEf",
        "outputId": "ac5ef937-4035-4eb4-fab8-3d02a9dad61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 2]), torch.Size([1, 2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## permuting tensor's dimensions\n",
        "tensor = torch.rand(224, 224, 3) #[height, width, colour_channels]\n",
        "\n",
        "tensor_permuted = torch.permute(tensor, (2, 0, 1)) #[colour_channels, height, width]\n",
        "tensor.shape, tensor_permuted.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6z6C3-GPwH-",
        "outputId": "b36f0875-2511-4db9-d3f5-60404df2f6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Indexing tensors(selecting data)**"
      ],
      "metadata": {
        "id": "JhQMjKqg63m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.zeros(1, 2, 2)\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0AfPPCo68B4",
        "outputId": "5949a5c2-ea15-4242-c227-4289786ee0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOIwBKK47Ko5",
        "outputId": "1ce22182-3971-442f-99f7-448961fdc595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[0][0], tensor[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msS7cJlT7N0A",
        "outputId": "4aac7028-43ed-4ba9-8691-0e58e33b824c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0.]), tensor([0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[0][0][0], tensor[0, 0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpFSp98Z7QJQ",
        "outputId": "038ecb73-5048-4fc8-e9f8-0d55e7c1c7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also use \":\" to select \"all\" of a target dimension\n",
        "tensor[0, 0, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMeby5Ed7kGp",
        "outputId": "6c40e7b8-4bb0-493d-ac5d-5c3e9b93f586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[:, :, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydDE0QCw7_Eb",
        "outputId": "45d34ab2-56b4-4b49-f30c-c1f6dd49a6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[:, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vq9_gU68UpJ",
        "outputId": "d77fd0a3-39ea-46c3-9cb5-0b6f4ca6e188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy and PyTorch**\n",
        "\n",
        "PyTorch accepts data from numPy as input\n",
        "\n",
        "`torch.from_numpy(np_array)`\n",
        "\n",
        "`torch.Tensor.numpy()`"
      ],
      "metadata": {
        "id": "Q1V6bUxe9uTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# NumPy to tensor\n",
        "array = np.arange(1, 8)\n",
        "tensor = torch.from_numpy(array) # note that converting a numpy array to a tensor keeps the same data type\n",
        "array.dtype, tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_CNgOlY-KFl",
        "outputId": "d386700d-c3cc-4373-8587-5b8baced93c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor to NumPy\n",
        "tensor = torch.ones(5)\n",
        "numpy_array = tensor.numpy()\n",
        "tensor, numpy_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSeDQs2qADO5",
        "outputId": "afe25e53-dd08-4234-d4e1-553f39117574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reproducibility(making random inputs reproducible)**\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/randomness.html"
      ],
      "metadata": {
        "id": "tEiI9LkhWoTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# if we set a seed we can reproduce the generation of random numbers\n",
        "torch.manual_seed(4)\n",
        "random_tensor_1 = torch.rand(2, 2)\n",
        "random_tensor_2 = torch.rand(2, 2)\n",
        "\n",
        "print(random_tensor_1)\n",
        "print(random_tensor_2)\n",
        "print(random_tensor_1 == random_tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ6KoLMcZzJd",
        "outputId": "1ef4b919-99ac-48a8-bd32-082675f685cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5596, 0.5591],\n",
            "        [0.0915, 0.2100]])\n",
            "tensor([[0.0072, 0.0390],\n",
            "        [0.9929, 0.9131]])\n",
            "tensor([[False, False],\n",
            "        [False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so if we reuse the seed, we will end up getting the same random numbers\n",
        "# and reproducing our randomness\n",
        "torch.manual_seed(4)\n",
        "random_tensor_3 = torch.rand(2, 2)\n",
        "random_tensor_4 = torch.rand(2, 2)\n",
        "\n",
        "print(random_tensor_3)\n",
        "print(random_tensor_4)\n",
        "print(random_tensor_1 == random_tensor_3)\n",
        "print(random_tensor_2 == random_tensor_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUABLGJlacHp",
        "outputId": "616f5073-8172-4a72-e39c-60f51a2ebf01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5596, 0.5591],\n",
            "        [0.0915, 0.2100]])\n",
            "tensor([[0.0072, 0.0390],\n",
            "        [0.9929, 0.9131]])\n",
            "tensor([[True, True],\n",
            "        [True, True]])\n",
            "tensor([[True, True],\n",
            "        [True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up a gpu in PyTorch**\n",
        "\n",
        "https://pytorch.org/tutorials/recipes/recipes/changing_default_device.html"
      ],
      "metadata": {
        "id": "HiLAqHP1rP9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Putting tensors(and models) in a gpu**"
      ],
      "metadata": {
        "id": "BHizajEArW00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# When we create a tensor, it's by default on the CPU\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiT_VdiSrro5",
        "outputId": "ea6b4a2f-8bfc-414a-8a01-83b2884cb16f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to move the tensor to a gpu for faster computation\n",
        "tensor = tensor.to(device=\"cuda\")\n",
        "tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OHwIPh9sB2m",
        "outputId": "d47b4b9e-b284-424f-a37c-149670845e8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to set all of tensors by default on gpu we may run:\n",
        "torch.set_default_device('cuda')\n",
        "\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor_2 = torch.rand(1, 2)\n",
        "tensor.device, tensor_2.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjnspA-xsnoh",
        "outputId": "afe672b3-18c1-4703-801c-08ee49dac50f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), device(type='cuda', index=0))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy does not accept data on the GPU, so if we need to use NumPy we first need to get the tensor back to the CPU with:\n",
        "`Tensor.cpu()`"
      ],
      "metadata": {
        "id": "YXEfvanis_D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tensor.cpu()\n",
        "tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yge2FmrJtu_l",
        "outputId": "6c366b77-aca3-4cba-a89a-6cbdab29ab4f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}